{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7b3216",
   "metadata": {},
   "source": [
    "# ejemplo tomado de la sección de comentarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30395f5c",
   "metadata": {},
   "source": [
    "### Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n",
    "    CATBOOST_MODEL_PATH = \"/kaggle/input/nfl-2026-big-data-bowl/catboost_5fold_models.pkl\"\n",
    "    LSTM_MODEL_DIR = \"/kaggle/input/d/mathieuduverne/big-data-bowl-2026-dynamic-specs-nn/output\"\n",
    "    \n",
    "    ENSEMBLE_WEIGHTS = {\n",
    "        'catboost': 0.5,\n",
    "        'lstm': 0.5\n",
    "    }\n",
    "    \n",
    "    ROLE_SPECIFIC_WEIGHTS = {\n",
    "        'Passer': {'catboost': 0.6, 'lstm': 0.4},\n",
    "        'Targeted Receiver': {'catboost': 0.4, 'lstm': 0.6},\n",
    "        'Defensive Coverage': {'catboost': 0.45, 'lstm': 0.55},\n",
    "        'default': {'catboost': 0.5, 'lstm': 0.5}\n",
    "    }\n",
    "    \n",
    "    USE_ROLE_SPECIFIC_WEIGHTS = False\n",
    "    \n",
    "    LSTM_N_FOLDS = 5\n",
    "    LSTM_WINDOW_SIZE = 8\n",
    "    \n",
    "    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n",
    "    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62062ad0",
   "metadata": {},
   "source": [
    "### catboost pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f270df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_catboost_models(model_path):\n",
    "    \"\"\"Load pre-trained CatBoost models\"\"\"\n",
    "    with open(model_path, 'rb') as f:\n",
    "        saved = pickle.load(f)\n",
    "    return saved['models_x'], saved['models_y'], saved['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b13a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_catboost_features(df):\n",
    "    \"\"\"Create physics-based features for CatBoost models\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['velocity_x'] = df['s'] * np.cos(np.radians(df['dir']))\n",
    "    df['velocity_y'] = df['s'] * np.sin(np.radians(df['dir']))\n",
    "    \n",
    "    df['dist_to_ball'] = np.sqrt(\n",
    "        (df['x'] - df['ball_land_x'])**2 + \n",
    "        (df['y'] - df['ball_land_y'])**2\n",
    "    )\n",
    "    \n",
    "    df['angle_to_ball'] = np.arctan2(\n",
    "        df['ball_land_y'] - df['y'],\n",
    "        df['ball_land_x'] - df['x']\n",
    "    )\n",
    "    \n",
    "    df['velocity_toward_ball'] = (\n",
    "        df['velocity_x'] * np.cos(df['angle_to_ball']) + \n",
    "        df['velocity_y'] * np.sin(df['angle_to_ball'])\n",
    "    )\n",
    "    \n",
    "    df['time_to_ball'] = df['num_frames_output'] / 10.0\n",
    "    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n",
    "    df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n",
    "    \n",
    "    df['role_targeted_receiver'] = (df['player_role'] == 'Targeted Receiver').astype(int)\n",
    "    df['role_defensive_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n",
    "    df['role_passer'] = (df['player_role'] == 'Passer').astype(int)\n",
    "    df['side_offense'] = (df['player_side'] == 'Offense').astype(int)\n",
    "    \n",
    "    height_parts = df['player_height'].str.split('-', expand=True)\n",
    "    df['height_inches'] = height_parts[0].astype(float) * 12 + height_parts[1].astype(float)\n",
    "    df['bmi'] = (df['player_weight'] / (df['height_inches']**2)) * 703\n",
    "    \n",
    "    df['acceleration_x'] = df['a'] * np.cos(np.radians(df['dir']))\n",
    "    df['acceleration_y'] = df['a'] * np.sin(np.radians(df['dir']))\n",
    "    df['distance_to_target_x'] = df['ball_land_x'] - df['x']\n",
    "    df['distance_to_target_y'] = df['ball_land_y'] - df['y']\n",
    "    df['speed_squared'] = df['s'] ** 2\n",
    "    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n",
    "    df['velocity_alignment'] = np.cos(df['angle_to_ball'] - np.radians(df['dir']))\n",
    "    \n",
    "    df['expected_x_at_ball'] = df['x'] + df['velocity_x'] * df['time_to_ball']\n",
    "    df['expected_y_at_ball'] = df['y'] + df['velocity_y'] * df['time_to_ball']\n",
    "    df['error_from_ball_x'] = df['expected_x_at_ball'] - df['ball_land_x']\n",
    "    df['error_from_ball_y'] = df['expected_y_at_ball'] - df['ball_land_y']\n",
    "    df['error_from_ball'] = np.sqrt(df['error_from_ball_x']**2 + df['error_from_ball_y']**2)\n",
    "    \n",
    "    df['momentum_x'] = df['player_weight'] * df['velocity_x']\n",
    "    df['momentum_y'] = df['player_weight'] * df['velocity_y']\n",
    "    df['kinetic_energy'] = 0.5 * df['player_weight'] * df['speed_squared']\n",
    "    \n",
    "    df['angle_diff'] = np.abs(df['o'] - np.degrees(df['angle_to_ball']))\n",
    "    df['angle_diff'] = np.minimum(df['angle_diff'], 360 - df['angle_diff'])\n",
    "    \n",
    "    df['time_squared'] = df['time_to_ball'] ** 2\n",
    "    df['dist_squared'] = df['dist_to_ball'] ** 2\n",
    "    df['weighted_dist_by_time'] = df['dist_to_ball'] / (df['time_to_ball'] + 0.1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2faa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sequence_features_catboost(df):\n",
    "    \"\"\"Add temporal features using lag and rolling statistics\"\"\"\n",
    "    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    group_cols = ['game_id', 'play_id', 'nfl_id']\n",
    "    \n",
    "    for lag in [1, 2, 3, 4, 5]:\n",
    "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's', 'a']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_lag{lag}'] = df.groupby(group_cols)[col].shift(lag)\n",
    "    \n",
    "    for window in [3, 5]:\n",
    "        for col in ['x', 'y', 'velocity_x', 'velocity_y', 's']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_rolling_mean_{window}'] = df.groupby(group_cols)[col].rolling(window, min_periods=1).mean().reset_index(level=[0,1,2], drop=True)\n",
    "                df[f'{col}_rolling_std_{window}'] = df.groupby(group_cols)[col].rolling(window, min_periods=1).std().reset_index(level=[0,1,2], drop=True)\n",
    "    \n",
    "    for col in ['velocity_x', 'velocity_y']:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_delta'] = df.groupby(group_cols)[col].diff()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09410ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_catboost(models_x, models_y, features, test_input, test_template):\n",
    "    \"\"\"Generate predictions from CatBoost ensemble\"\"\"\n",
    "    test_features = engineer_catboost_features(test_input)\n",
    "    test_features = add_sequence_features_catboost(test_features)\n",
    "    \n",
    "    test_agg = test_features.groupby(['game_id', 'play_id', 'nfl_id']).last().reset_index()\n",
    "    if 'frame_id' in test_agg.columns:\n",
    "        test_agg = test_agg.drop('frame_id', axis=1)\n",
    "    \n",
    "    test_merged = test_template.merge(\n",
    "        test_agg,\n",
    "        on=['game_id', 'play_id', 'nfl_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    for col in features:\n",
    "        if col not in test_merged.columns:\n",
    "            test_merged[col] = 0\n",
    "    \n",
    "    X_test = test_merged[features].fillna(0).values\n",
    "    \n",
    "    pred_x = np.mean([model.predict(X_test) for model in models_x], axis=0)\n",
    "    pred_y = np.mean([model.predict(X_test) for model in models_y], axis=0)\n",
    "    \n",
    "    predictions = pd.DataFrame({\n",
    "        'id': (test_merged['game_id'].astype(str) + '_' + \n",
    "              test_merged['play_id'].astype(str) + '_' + \n",
    "              test_merged['nfl_id'].astype(str) + '_' + \n",
    "              test_merged['frame_id'].astype(str)),\n",
    "        'x': pred_x,\n",
    "        'y': pred_y\n",
    "    })\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4261e8e",
   "metadata": {},
   "source": [
    "### LSTM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(torch.nn.Module):\n",
    "    def __init__(self, mod, dim_in, dim_out, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.mod = mod\n",
    "        self.proj = torch.nn.Identity() if dim_in == dim_out else torch.nn.Linear(dim_in, dim_out)\n",
    "        self.dropout = torch.nn.Dropout(drop_prob)\n",
    "    def forward(self, x):\n",
    "        y = self.mod(x)\n",
    "        x_proj = self.proj(x)\n",
    "        return self.dropout(y) + x_proj\n",
    "\n",
    "class RNNBlock(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, rnn=\"gru\", num_layers=1, dropout=0.1, bidirectional=False):\n",
    "        super().__init__()\n",
    "        rnn_cls = torch.nn.GRU if rnn.lower() == \"gru\" else torch.nn.LSTM\n",
    "        self.rnn = rnn_cls(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                          batch_first=True, dropout=dropout if num_layers > 1 else 0, bidirectional=bidirectional)\n",
    "        self.out_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "    def forward(self, x):\n",
    "        y, _ = self.rnn(x)\n",
    "        return y\n",
    "\n",
    "class Conv1DBlock(torch.nn.Module):\n",
    "    def __init__(self, dim, kernel_size=3, dilation=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        pad = (kernel_size - 1) * dilation // 2\n",
    "        self.pre_ln = torch.nn.LayerNorm(dim)\n",
    "        self.dw = torch.nn.Conv1d(dim, dim, kernel_size, padding=pad, dilation=dilation, groups=dim)\n",
    "        self.pw = torch.nn.Conv1d(dim, dim, 1)\n",
    "        self.act = torch.nn.GELU()\n",
    "        self.drop = torch.nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        y = self.pre_ln(x)\n",
    "        y = y.transpose(1, 2)\n",
    "        y = self.dw(y)\n",
    "        y = self.act(y)\n",
    "        y = self.pw(y)\n",
    "        y = self.drop(y)\n",
    "        return y.transpose(1, 2)\n",
    "\n",
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, dim, nhead=4, ff_mult=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = torch.nn.LayerNorm(dim)\n",
    "        self.attn = torch.nn.MultiheadAttention(dim, num_heads=nhead, dropout=dropout, batch_first=True)\n",
    "        self.ln2 = torch.nn.LayerNorm(dim)\n",
    "        self.ff = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, ff_mult * dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(ff_mult * dim, dim),\n",
    "            torch.nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
    "        h = self.ln1(x)\n",
    "        y, _ = self.attn(h, h, h, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
    "        x = x + y\n",
    "        h = self.ln2(x)\n",
    "        h = x + self.ff(h)\n",
    "        return h\n",
    "\n",
    "class SEBlock(torch.nn.Module):\n",
    "    def __init__(self, dim, r=4):\n",
    "        super().__init__()\n",
    "        hidden = max(1, dim // r)\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden, dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        s = x.mean(dim=1)\n",
    "        g = self.net(s).unsqueeze(1)\n",
    "        return x * g\n",
    "\n",
    "class TransformerBlockWrapper(torch.nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class FlexibleSeqModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, horizon: int, block_specs: list, dropout: float = 0.2,\n",
    "                 pooling: str = \"attn\", predict_mode: str = \"steps\", attn_pool_heads: int = 4):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        self.predict_mode = predict_mode\n",
    "        self.pooling = pooling\n",
    "        dim = input_dim\n",
    "        blocks = []\n",
    "        for spec in block_specs:\n",
    "            t = spec[\"type\"].lower()\n",
    "            if t == \"rnn\":\n",
    "                blk = RNNBlock(input_dim=dim, hidden_dim=spec.get(\"hidden\", 128), rnn=spec.get(\"rnn\", \"gru\"),\n",
    "                              num_layers=spec.get(\"layers\", 1), dropout=spec.get(\"dropout\", 0.1),\n",
    "                              bidirectional=spec.get(\"bidirectional\", False))\n",
    "                blocks.append(Residual(blk, dim, blk.out_dim, drop_prob=spec.get(\"res_dropout\", 0.0)))\n",
    "                dim = blk.out_dim\n",
    "            elif t == \"tcn\":\n",
    "                blk = Conv1DBlock(dim, kernel_size=spec.get(\"kernel\", 3), dilation=spec.get(\"dilation\", 1),\n",
    "                                 dropout=spec.get(\"dropout\", 0.1))\n",
    "                blocks.append(Residual(blk, dim, dim, drop_prob=spec.get(\"res_dropout\", 0.0)))\n",
    "            elif t == \"transformer\":\n",
    "                blk = TransformerBlock(dim, nhead=spec.get(\"nhead\", 4), ff_mult=spec.get(\"ff_mult\", 4),\n",
    "                                      dropout=spec.get(\"dropout\", 0.1))\n",
    "                blocks.append(Residual(TransformerBlockWrapper(blk), dim, dim, drop_prob=spec.get(\"res_dropout\", 0.0)))\n",
    "            elif t == \"se\":\n",
    "                blk = SEBlock(dim, r=spec.get(\"r\", 4))\n",
    "                blocks.append(Residual(blk, dim, dim, drop_prob=spec.get(\"res_dropout\", 0.0)))\n",
    "        self.blocks = torch.nn.ModuleList(blocks)\n",
    "        if pooling == \"attn\":\n",
    "            self.pool_ln = torch.nn.LayerNorm(dim)\n",
    "            self.pool_attn = torch.nn.MultiheadAttention(dim, num_heads=attn_pool_heads, batch_first=True)\n",
    "            self.pool_vec = torch.nn.Parameter(torch.randn(1, 1, dim))\n",
    "        elif pooling == \"mean\":\n",
    "            self.pool_ln = torch.nn.LayerNorm(dim)\n",
    "        else:\n",
    "            self.pool_ln = torch.nn.LayerNorm(dim)\n",
    "        self.head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, 128),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(128, horizon)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        for blk in self.blocks:\n",
    "            h = blk(h)\n",
    "        if self.pooling == \"attn\":\n",
    "            B, T, D = h.shape\n",
    "            q = self.pool_vec.expand(B, -1, -1)\n",
    "            k = v = self.pool_ln(h)\n",
    "            ctx, _ = self.pool_attn(q, k, v)\n",
    "            ctx = ctx.squeeze(1)\n",
    "        elif self.pooling == \"mean\":\n",
    "            ctx = self.pool_ln(h).mean(dim=1)\n",
    "        else:\n",
    "            ctx = self.pool_ln(h[:, -1, :])\n",
    "        out = self.head(ctx)\n",
    "        if self.predict_mode == \"steps\":\n",
    "            out = torch.cumsum(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lstm_models(models_dir, n_folds):\n",
    "    \"\"\"Load pre-trained LSTM models for both axes\"\"\"\n",
    "    models_x, models_y, scalers = [], [], []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for fold in range(n_folds):\n",
    "        model_x_path = Path(models_dir) / f'fold_{fold+1}/axis_x.pt'\n",
    "        model_y_path = Path(models_dir) / f'fold_{fold+1}/axis_y.pt'\n",
    "        scaler_path = Path(models_dir) / f'fold_{fold+1}/lstm_feature_scaler_fold.joblib'\n",
    "        \n",
    "        ckpt_x = torch.load(model_x_path, map_location=device)\n",
    "        ckpt_y = torch.load(model_y_path, map_location=device)\n",
    "        \n",
    "        cfg_x = ckpt_x.get('config', {})\n",
    "        input_dim = cfg_x.get('input_dim')\n",
    "        horizon = cfg_x.get('horizon')\n",
    "        \n",
    "        block_specs = [\n",
    "            {\"type\": \"rnn\", \"rnn\": \"gru\", \"hidden\": 128, \"layers\": 1, \"dropout\": 0.1},\n",
    "            {\"type\": \"transformer\", \"nhead\": 4, \"ff_mult\": 4, \"dropout\": 0.1},\n",
    "            {\"type\": \"tcn\", \"kernel\": 3, \"dilation\": 2, \"dropout\": 0.1},\n",
    "        ]\n",
    "        \n",
    "        model_x = FlexibleSeqModel(input_dim=input_dim, horizon=horizon, block_specs=block_specs,\n",
    "                                   pooling=\"mean\", predict_mode=\"steps\", dropout=0.2)\n",
    "        model_y = FlexibleSeqModel(input_dim=input_dim, horizon=horizon, block_specs=block_specs,\n",
    "                                   pooling=\"mean\", predict_mode=\"steps\", dropout=0.2)\n",
    "        \n",
    "        model_x.load_state_dict(ckpt_x['state_dict'])\n",
    "        model_y.load_state_dict(ckpt_y['state_dict'])\n",
    "        \n",
    "        model_x.to(device).eval()\n",
    "        model_y.to(device).eval()\n",
    "        \n",
    "        models_x.append(model_x)\n",
    "        models_y.append(model_y)\n",
    "        scalers.append(joblib.load(scaler_path))\n",
    "    \n",
    "    return models_x, models_y, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12528630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_to_feet(height_str):\n",
    "    try:\n",
    "        ft, inches = map(int, height_str.split('-'))\n",
    "        return ft + inches/12\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c045f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_sequences(input_df, test_template, window_size):\n",
    "    \"\"\"Prepare sequential features for LSTM inference\"\"\"\n",
    "    input_df = input_df.copy()\n",
    "    input_df['player_height_feet'] = input_df['player_height'].map(height_to_feet)\n",
    "    \n",
    "    dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n",
    "    delta_t = 0.1\n",
    "    input_df['velocity_x'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.sin(dir_rad)\n",
    "    input_df['velocity_y'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.cos(dir_rad)\n",
    "    \n",
    "    input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n",
    "    input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n",
    "    input_df['is_receiver'] = (input_df['player_role'] == 'Receiver').astype(int)\n",
    "    input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n",
    "    input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n",
    "    \n",
    "    mass_kg = input_df['player_weight'].fillna(200.0) / 2.20462\n",
    "    input_df['momentum_x'] = input_df['velocity_x'] * mass_kg\n",
    "    input_df['momentum_y'] = input_df['velocity_y'] * mass_kg\n",
    "    \n",
    "    from datetime import datetime\n",
    "    current_date = datetime.now()\n",
    "    input_df['age'] = input_df['player_birth_date'].apply(\n",
    "        lambda x: (current_date - datetime.strptime(x, '%Y-%m-%d')).days // 365 if pd.notnull(x) else None\n",
    "    )\n",
    "    \n",
    "    input_df['kinetic_energy'] = 0.5 * mass_kg * (input_df['s'] ** 2)\n",
    "    input_df['force'] = mass_kg * input_df['a']\n",
    "    \n",
    "    input_df['rolling_mean_velocity_x'] = input_df.groupby(['game_id', 'play_id', 'nfl_id'])['velocity_x'].transform(\n",
    "        lambda x: x.rolling(window=window_size, min_periods=1).mean()\n",
    "    )\n",
    "    input_df['rolling_std_acceleration'] = input_df.groupby(['game_id', 'play_id', 'nfl_id'])['a'].transform(\n",
    "        lambda x: x.rolling(window=window_size, min_periods=1).std()\n",
    "    )\n",
    "    \n",
    "    if all(col in input_df.columns for col in ['ball_land_x', 'ball_land_y']):\n",
    "        ball_dx = input_df['ball_land_x'] - input_df['x']\n",
    "        ball_dy = input_df['ball_land_y'] - input_df['y']\n",
    "        input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n",
    "        input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n",
    "        input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['closing_speed'] = (input_df['velocity_x'] * input_df['ball_direction_x'] +\n",
    "                                     input_df['velocity_y'] * input_df['ball_direction_y'])\n",
    "        input_df['estimated_time_to_ball'] = input_df['distance_to_ball'] / 20.0\n",
    "        input_df['projected_time_to_ball'] = input_df['distance_to_ball'] / (np.abs(input_df['closing_speed']) + 0.1)\n",
    "    \n",
    "    input_df['heading_x'] = np.sin(dir_rad)\n",
    "    input_df['heading_y'] = np.cos(dir_rad)\n",
    "    input_df['acceleration_x'] = input_df['a'] * input_df['heading_x']\n",
    "    input_df['acceleration_y'] = input_df['a'] * input_df['heading_y']\n",
    "    input_df['accel_magnitude'] = np.sqrt(input_df['acceleration_x']**2 + input_df['acceleration_y']**2)\n",
    "    \n",
    "    agg_rows = []\n",
    "    for (g, p, f), grp in input_df.groupby(['game_id', 'play_id', 'frame_id'], sort=False):\n",
    "        n = len(grp)\n",
    "        nfl_ids = grp['nfl_id'].to_numpy()\n",
    "        if n < 2:\n",
    "            for nid in nfl_ids:\n",
    "                agg_rows.append({\n",
    "                    'game_id': g, 'play_id': p, 'frame_id': f, 'nfl_id': nid,\n",
    "                    'distance_to_player_mean_offense': np.nan, 'distance_to_player_min_offense': np.nan, 'distance_to_player_max_offense': np.nan,\n",
    "                    'relative_velocity_magnitude_mean_offense': np.nan, 'relative_velocity_magnitude_min_offense': np.nan, 'relative_velocity_magnitude_max_offense': np.nan,\n",
    "                    'angle_to_player_mean_offense': np.nan, 'angle_to_player_min_offense': np.nan, 'angle_to_player_max_offense': np.nan,\n",
    "                    'distance_to_player_mean_defense': np.nan, 'distance_to_player_min_defense': np.nan, 'distance_to_player_max_defense': np.nan,\n",
    "                    'relative_velocity_magnitude_mean_defense': np.nan, 'relative_velocity_magnitude_min_defense': np.nan, 'relative_velocity_magnitude_max_defense': np.nan,\n",
    "                    'angle_to_player_mean_defense': np.nan, 'angle_to_player_min_defense': np.nan, 'angle_to_player_max_defense': np.nan,\n",
    "                })\n",
    "            continue\n",
    "        x = grp['x'].to_numpy(dtype=np.float32)\n",
    "        y = grp['y'].to_numpy(dtype=np.float32)\n",
    "        vx = grp['velocity_x'].to_numpy(dtype=np.float32)\n",
    "        vy = grp['velocity_y'].to_numpy(dtype=np.float32)\n",
    "        is_offense = grp['is_offense'].to_numpy()\n",
    "        is_defense = grp['is_defense'].to_numpy()\n",
    "        dx = x[None, :] - x[:, None]\n",
    "        dy = y[None, :] - y[:, None]\n",
    "        angle_mat = np.arctan2(-dy, -dx)\n",
    "        dist = np.sqrt(dx ** 2 + dy ** 2)\n",
    "        dvx = vx[:, None] - vx[None, :]\n",
    "        dvy = vy[:, None] - vy[None, :]\n",
    "        rel_speed = np.sqrt(dvx ** 2 + dvy ** 2)\n",
    "        offense_mask = (is_offense[:, None] == is_offense[None, :])\n",
    "        np.fill_diagonal(offense_mask, False)\n",
    "        defense_mask = (is_defense[:, None] == is_defense[None, :])\n",
    "        np.fill_diagonal(defense_mask, False)\n",
    "        dist_diag_nan = dist.copy()\n",
    "        np.fill_diagonal(dist_diag_nan, np.nan)\n",
    "        rel_diag_nan = rel_speed.copy()\n",
    "        np.fill_diagonal(rel_diag_nan, np.nan)\n",
    "        angle_diag_nan = angle_mat.copy()\n",
    "        np.fill_diagonal(angle_diag_nan, np.nan)\n",
    "        def masked_stats(mat, mask):\n",
    "            masked = np.where(mask, mat, np.nan)\n",
    "            cnt = mask.sum(axis=1)\n",
    "            mean = np.nanmean(masked, axis=1)\n",
    "            amin = np.nanmin(masked, axis=1)\n",
    "            amax = np.nanmax(masked, axis=1)\n",
    "            zero = cnt == 0\n",
    "            mean[zero] = np.nan; amin[zero] = np.nan; amax[zero] = np.nan\n",
    "            return mean, amin, amax\n",
    "        d_mean_o, d_min_o, d_max_o = masked_stats(dist_diag_nan, offense_mask)\n",
    "        v_mean_o, v_min_o, v_max_o = masked_stats(rel_diag_nan, offense_mask)\n",
    "        a_mean_o, a_min_o, a_max_o = masked_stats(angle_diag_nan, offense_mask)\n",
    "        d_mean_d, d_min_d, d_max_d = masked_stats(dist_diag_nan, defense_mask)\n",
    "        v_mean_d, v_min_d, v_max_d = masked_stats(rel_diag_nan, defense_mask)\n",
    "        a_mean_d, a_min_d, a_max_d = masked_stats(angle_diag_nan, defense_mask)\n",
    "        for idx, nid in enumerate(nfl_ids):\n",
    "            agg_rows.append({\n",
    "                'game_id': g, 'play_id': p, 'frame_id': f, 'nfl_id': nid,\n",
    "                'distance_to_player_mean_offense': d_mean_o[idx], 'distance_to_player_min_offense': d_min_o[idx], 'distance_to_player_max_offense': d_max_o[idx],\n",
    "                'relative_velocity_magnitude_mean_offense': v_mean_o[idx], 'relative_velocity_magnitude_min_offense': v_min_o[idx], 'relative_velocity_magnitude_max_offense': v_max_o[idx],\n",
    "                'angle_to_player_mean_offense': a_mean_o[idx], 'angle_to_player_min_offense': a_min_o[idx], 'angle_to_player_max_offense': a_max_o[idx],\n",
    "                'distance_to_player_mean_defense': d_mean_d[idx], 'distance_to_player_min_defense': d_min_d[idx], 'distance_to_player_max_defense': d_max_d[idx],\n",
    "                'relative_velocity_magnitude_mean_defense': v_mean_d[idx], 'relative_velocity_magnitude_min_defense': v_min_d[idx], 'relative_velocity_magnitude_max_defense': v_max_d[idx],\n",
    "                'angle_to_player_mean_defense': a_mean_d[idx], 'angle_to_player_min_defense': a_min_d[idx], 'angle_to_player_max_defense': a_max_d[idx],\n",
    "            })\n",
    "    interaction_agg = pd.DataFrame(agg_rows)\n",
    "    input_df = input_df.merge(interaction_agg, on=['game_id', 'play_id', 'frame_id', 'nfl_id'], how='left')\n",
    "    \n",
    "    input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n",
    "    \n",
    "    feature_cols = [\n",
    "        'x','y','s','a','o','dir','frame_id','ball_land_x','ball_land_y',\n",
    "        'absolute_yardline_number',\n",
    "        'player_height_feet','player_weight',\n",
    "        'velocity_x','velocity_y',\n",
    "        'momentum_x','momentum_y',\n",
    "        'is_offense','is_defense','is_receiver','is_coverage','is_passer',\n",
    "        'age','kinetic_energy','force',\n",
    "        'rolling_mean_velocity_x','rolling_std_acceleration',\n",
    "        'heading_x','heading_y','acceleration_x','acceleration_y','accel_magnitude',\n",
    "        'distance_to_ball','angle_to_ball','ball_direction_x','ball_direction_y',\n",
    "        'closing_speed','estimated_time_to_ball','projected_time_to_ball',\n",
    "        'distance_to_ball','angle_to_ball','ball_direction_x','ball_direction_y',\n",
    "        'closing_speed','estimated_time_to_ball','projected_time_to_ball',\n",
    "        'distance_to_player_mean_offense','distance_to_player_min_offense','distance_to_player_max_offense',\n",
    "        'relative_velocity_magnitude_mean_offense','relative_velocity_magnitude_min_offense','relative_velocity_magnitude_max_offense',\n",
    "        'angle_to_player_mean_offense','angle_to_player_min_offense','angle_to_player_max_offense',\n",
    "        'distance_to_player_mean_defense','distance_to_player_min_defense','distance_to_player_max_defense',\n",
    "        'relative_velocity_magnitude_mean_defense','relative_velocity_magnitude_min_defense','relative_velocity_magnitude_max_defense',\n",
    "        'angle_to_player_mean_defense','angle_to_player_min_defense','angle_to_player_max_defense'\n",
    "    ]\n",
    "    \n",
    "    grouped_input = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n",
    "    target_groups = test_template[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n",
    "    \n",
    "    sequences, sequence_ids = [], []\n",
    "    \n",
    "    for _, row in target_groups.iterrows():\n",
    "        key = (row['game_id'], row['play_id'], row['nfl_id'])\n",
    "        try:\n",
    "            group_df = grouped_input.get_group(key)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        input_window = group_df.tail(window_size)\n",
    "        \n",
    "        if len(input_window) < window_size:\n",
    "            pad_length = window_size - len(input_window)\n",
    "            pad_df = pd.DataFrame(np.nan, index=range(pad_length), columns=input_window.columns)\n",
    "            input_window = pd.concat([pad_df, input_window], ignore_index=True).reset_index(drop=True)\n",
    "        \n",
    "        seq = input_window[feature_cols].values\n",
    "        \n",
    "        if np.isnan(seq.astype(np.float32)).any():\n",
    "            seq = np.nan_to_num(seq, nan=0.0)\n",
    "        \n",
    "        sequences.append(seq)\n",
    "        \n",
    "        last_frame_id = input_window['frame_id'].iloc[-1]\n",
    "        sequence_ids.append({\n",
    "            'game_id': key[0],\n",
    "            'play_id': key[1],\n",
    "            'nfl_id': key[2],\n",
    "            'frame_id': last_frame_id\n",
    "        })\n",
    "    \n",
    "    return sequences, sequence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lstm(models_x, models_y, scalers, test_input, test_template):\n",
    "    \"\"\"Generate predictions from LSTM ensemble\"\"\"\n",
    "    sequences, seq_ids = prepare_lstm_sequences(test_input, test_template, Config.LSTM_WINDOW_SIZE)\n",
    "    X_test_unscaled = np.array(sequences, dtype=object)\n",
    "    test_meta = pd.DataFrame(seq_ids)\n",
    "    \n",
    "    x_last = np.array([seq[-1, 0] for seq in X_test_unscaled], dtype=np.float32)\n",
    "    y_last = np.array([seq[-1, 1] for seq in X_test_unscaled], dtype=np.float32)\n",
    "    test_meta['x_last'] = x_last\n",
    "    test_meta['y_last'] = y_last\n",
    "    \n",
    "    per_model_dx, per_model_dy = [], []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for i, (model_x, model_y, scaler) in enumerate(zip(models_x, models_y, scalers)):\n",
    "        scaled = np.array([scaler.transform(s) for s in X_test_unscaled], dtype=object)\n",
    "        stacked = np.stack(scaled.astype(np.float32))\n",
    "        test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(stacked))\n",
    "        loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "        \n",
    "        dx_list, dy_list = [], []\n",
    "        with torch.no_grad():\n",
    "            for (batch,) in loader:\n",
    "                batch = batch.to(device)\n",
    "                dx = model_x(batch).cpu().numpy()\n",
    "                dy = model_y(batch).cpu().numpy()\n",
    "                dx_list.append(dx)\n",
    "                dy_list.append(dy)\n",
    "        \n",
    "        dx_cum = np.vstack(dx_list)\n",
    "        dy_cum = np.vstack(dy_list)\n",
    "        per_model_dx.append(dx_cum)\n",
    "        per_model_dy.append(dy_cum)\n",
    "    \n",
    "    ens_dx = np.mean(np.stack(per_model_dx, axis=0), axis=0)\n",
    "    ens_dy = np.mean(np.stack(per_model_dy, axis=0), axis=0)\n",
    "    \n",
    "    out_rows = []\n",
    "    for i, seq_info in test_meta.iterrows():\n",
    "        game_id = int(seq_info['game_id'])\n",
    "        play_id = int(seq_info['play_id'])\n",
    "        nfl_id = int(seq_info['nfl_id'])\n",
    "        \n",
    "        frame_ids = test_template[\n",
    "            (test_template['game_id'] == game_id) &\n",
    "            (test_template['play_id'] == play_id) &\n",
    "            (test_template['nfl_id'] == nfl_id)\n",
    "        ]['frame_id'].sort_values().tolist()\n",
    "        \n",
    "        for t, frame_id in enumerate(frame_ids):\n",
    "            if t < ens_dx.shape[1]:\n",
    "                px = x_last[i] + ens_dx[i, t]\n",
    "                py = y_last[i] + ens_dy[i, t]\n",
    "            else:\n",
    "                px = x_last[i] + ens_dx[i, -1]\n",
    "                py = y_last[i] + ens_dy[i, -1]\n",
    "            \n",
    "            out_rows.append({\n",
    "                'id': f\"{game_id}_{play_id}_{nfl_id}_{frame_id}\",\n",
    "                'x': px,\n",
    "                'y': py\n",
    "            })\n",
    "    \n",
    "    predictions = pd.DataFrame(out_rows)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c0634",
   "metadata": {},
   "source": [
    "## Estrategia de ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble(catboost_pred, lstm_pred, test_input, weights, use_role_specific=False, role_weights=None):\n",
    "    \"\"\"Combine predictions from both models using weighted averaging\"\"\"\n",
    "    assert set(catboost_pred['id']) == set(lstm_pred['id']), \"ID mismatch between models\"\n",
    "    \n",
    "    catboost_pred = catboost_pred.sort_values('id').reset_index(drop=True)\n",
    "    lstm_pred = lstm_pred.sort_values('id').reset_index(drop=True)\n",
    "    \n",
    "    if use_role_specific and role_weights is not None:\n",
    "        role_info = test_input[['game_id', 'play_id', 'nfl_id', 'player_role']].drop_duplicates()\n",
    "        role_info['id_prefix'] = (role_info['game_id'].astype(str) + '_' + \n",
    "                                  role_info['play_id'].astype(str) + '_' + \n",
    "                                  role_info['nfl_id'].astype(str))\n",
    "        \n",
    "        ensemble_rows = []\n",
    "        role_stats = {}\n",
    "        \n",
    "        for _, row in catboost_pred.iterrows():\n",
    "            pred_id = row['id']\n",
    "            id_prefix = '_'.join(pred_id.split('_')[:3])\n",
    "            \n",
    "            role_match = role_info[role_info['id_prefix'] == id_prefix]\n",
    "            if len(role_match) > 0:\n",
    "                role = role_match.iloc[0]['player_role']\n",
    "            else:\n",
    "                role = 'Unknown'\n",
    "            \n",
    "            if role in role_weights:\n",
    "                w_cat = role_weights[role]['catboost']\n",
    "                w_lstm = role_weights[role]['lstm']\n",
    "            else:\n",
    "                w_cat = role_weights['default']['catboost']\n",
    "                w_lstm = role_weights['default']['lstm']\n",
    "            \n",
    "            role_stats[role] = role_stats.get(role, 0) + 1\n",
    "            \n",
    "            total_weight = w_cat + w_lstm\n",
    "            lstm_row = lstm_pred[lstm_pred['id'] == pred_id].iloc[0]\n",
    "            \n",
    "            ensemble_rows.append({\n",
    "                'id': pred_id,\n",
    "                'x': (row['x'] * w_cat + lstm_row['x'] * w_lstm) / total_weight,\n",
    "                'y': (row['y'] * w_cat + lstm_row['y'] * w_lstm) / total_weight\n",
    "            })\n",
    "        \n",
    "        ensemble = pd.DataFrame(ensemble_rows)\n",
    "        print(\"\\nRole-specific weights applied:\")\n",
    "        for role, count in sorted(role_stats.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {role}: {count} predictions\")\n",
    "    else:\n",
    "        w_cat = weights['catboost']\n",
    "        w_lstm = weights['lstm']\n",
    "        total_weight = w_cat + w_lstm\n",
    "        \n",
    "        ensemble = pd.DataFrame({\n",
    "            'id': catboost_pred['id'],\n",
    "            'x': (catboost_pred['x'] * w_cat + lstm_pred['x'] * w_lstm) / total_weight,\n",
    "            'y': (catboost_pred['y'] * w_cat + lstm_pred['y'] * w_lstm) / total_weight\n",
    "        })\n",
    "    \n",
    "    ensemble['x'] = np.clip(ensemble['x'], Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n",
    "    ensemble['y'] = np.clip(ensemble['y'], Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n",
    "    \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862417d7",
   "metadata": {},
   "source": [
    "## Ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7249002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Loading test data...\")\n",
    "    test_input = pd.read_csv(Config.DATA_DIR / \"test_input.csv\")\n",
    "    test_template = pd.read_csv(Config.DATA_DIR / \"test.csv\")\n",
    "    print(f\"Test input: {test_input.shape[0]:,} rows, {test_input.shape[1]} columns\")\n",
    "    print(f\"Test template: {test_template.shape[0]:,} predictions required\")\n",
    "    \n",
    "    print(\"\\nLoading models...\")\n",
    "    models_x_cat, models_y_cat, features_cat = load_catboost_models(Config.CATBOOST_MODEL_PATH)\n",
    "    print(f\"CatBoost: {len(models_x_cat)} folds, {len(features_cat)} features\")\n",
    "    \n",
    "    models_x_lstm, models_y_lstm, scalers_lstm = load_lstm_models(Config.LSTM_MODEL_DIR, Config.LSTM_N_FOLDS)\n",
    "    print(f\"LSTM: {len(models_x_lstm)} folds loaded\")\n",
    "    \n",
    "    print(\"\\nGenerating CatBoost predictions...\")\n",
    "    catboost_pred = predict_catboost(models_x_cat, models_y_cat, features_cat, test_input, test_template)\n",
    "    print(f\"CatBoost predictions: {len(catboost_pred):,}\")\n",
    "    print(f\"  X range: [{catboost_pred['x'].min():.2f}, {catboost_pred['x'].max():.2f}]\")\n",
    "    print(f\"  Y range: [{catboost_pred['y'].min():.2f}, {catboost_pred['y'].max():.2f}]\")\n",
    "    \n",
    "    print(\"\\nGenerating LSTM predictions...\")\n",
    "    lstm_pred = predict_lstm(models_x_lstm, models_y_lstm, scalers_lstm, test_input, test_template)\n",
    "    print(f\"LSTM predictions: {len(lstm_pred):,}\")\n",
    "    print(f\"  X range: [{lstm_pred['x'].min():.2f}, {lstm_pred['x'].max():.2f}]\")\n",
    "    print(f\"  Y range: [{lstm_pred['y'].min():.2f}, {lstm_pred['y'].max():.2f}]\")\n",
    "    \n",
    "    print(\"\\nCreating ensemble...\")\n",
    "    ensemble_pred = create_ensemble(\n",
    "        catboost_pred, \n",
    "        lstm_pred, \n",
    "        test_input,\n",
    "        Config.ENSEMBLE_WEIGHTS,\n",
    "        use_role_specific=Config.USE_ROLE_SPECIFIC_WEIGHTS,\n",
    "        role_weights=Config.ROLE_SPECIFIC_WEIGHTS if Config.USE_ROLE_SPECIFIC_WEIGHTS else None\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEnsemble predictions: {len(ensemble_pred):,}\")\n",
    "    print(f\"  X range: [{ensemble_pred['x'].min():.2f}, {ensemble_pred['x'].max():.2f}]\")\n",
    "    print(f\"  Y range: [{ensemble_pred['y'].min():.2f}, {ensemble_pred['y'].max():.2f}]\")\n",
    "    print(f\"  Mean X: {ensemble_pred['x'].mean():.2f}, Std X: {ensemble_pred['x'].std():.2f}\")\n",
    "    print(f\"  Mean Y: {ensemble_pred['y'].mean():.2f}, Std Y: {ensemble_pred['y'].std():.2f}\")\n",
    "    print(f\"  NaN values: {ensemble_pred.isnull().sum().sum()}\")\n",
    "    \n",
    "    ensemble_pred.to_csv('submission.csv', index=False)\n",
    "    print(\"\\nSubmission file created successfully\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFL_NGS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
